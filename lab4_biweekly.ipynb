{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching methods are designed to generate estimates of the ATE or (much more commonly) the ATT by balancing, pruning and weighting your data. Matching methods are data-greedy; they work best when you have lots of observations to choose from. Typically, treated observations (those participating in the policy) will be matched with untreated observations. The untreated observations are thus used to provide the counterfactual: what would have been the case for our treated observations if they had not been treated. Or that, at least, is the idea.\n",
    "\n",
    "Let's install necessary packages (if needed) and load them: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# comment out any packages below that you already have installed\n",
    "\n",
    "install.packages(c(\n",
    "   'tidyverse',    # for data wrangling\n",
    "   'faux',         # for creating some fake data\n",
    "   'modelsummary', # for regression tables\n",
    "   'MatchIt',       # for matching\n",
    "   'haven'         # for loading different data formats\n",
    "))\n",
    "\n",
    "library(tidyverse)\n",
    "library(modelsummary)\n",
    "library(faux)\n",
    "library(MatchIt)\n",
    "library(haven)\n",
    "library(estimatr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some new data using the `faux` package. The package lets us draw random variables that are correlated with each other. The below function draws two variables with different scales from a multivariate normal distribution that are positively correlated at $r=.40$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df1 <- rnorm_multi( n = 1000,\n",
    "                    mu = c(7, 51),  # the means of the two vars\n",
    "                    sd = c(3, 20),  # the standard deviations\n",
    "                    r = .40,        # the correlation between the vars\n",
    "                    varnames = c(\"xvar1\", \n",
    "                                 \"xvar2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a treatment variable. Don't worry about the details here, but we are drawing a treatment variable, `treat` from the binomial distribution where the probability that the observation is treated (meaning: equals 1 rather than 0) is a function of our two conditioning variables `xvar1` and `xvar2` plus some random noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df1$treat <- rbinom(n = 1000, \n",
    "                    size = 1, \n",
    "                    prob = plogis(-16 + 1.2*df1$xvar1 + .08*df1$xvar2 + \n",
    "                                    rnorm(1000, 0, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create our outcome variable `yvar` as a linear function of our two conditioning variables and our treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df1$yvar <- -4 - 6.1*df1$treat + \n",
    "                4*df1$xvar1 + \n",
    "                .35*df1$xvar2 +\n",
    "                rnorm(1000, 0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly have selection bias. Our *X*s impact program participation (treatment). What happens if we simply examine the difference in outcomes based on observed treatment status?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# here we use a new tidyverse functions: pivot_wider\n",
    "# pivot_wider and pivot_longer are functions to transpose \n",
    "# rows and columns of a dataframe. In the code below,\n",
    "# we take the names of new columns from the variable `treat`\n",
    "# we fill the values from summarize() call generating means.\n",
    "# this lets us quick create a new variable that equals the \n",
    "# difference between the two means.\n",
    "\n",
    "# notice also that we can use ticks `` to access non-compliant\n",
    "# variable names like `mean of y` or `1`.\n",
    "\n",
    "\n",
    "df1 |>  group_by(treat) |> \n",
    "        summarize(\"mean of y\" = mean(yvar)) |>\n",
    "        pivot_wider(names_from = treat,\n",
    "                   values_from = `mean of y`) |>\n",
    "        mutate(\"diff in means\" = `1` - `0`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes. That isn't good at all. Recall that above, the ATE for `treat` is **-6.1**. We're *way* off in our estimate and the estimate is in the wrong direction. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing we could is use regression to condition on our confounding variables. `m1`-`m3` below all suffer from omitted variable bias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "m1 <- lm(yvar ~ treat, data = df1)\n",
    "m2 <- lm(yvar ~ treat + xvar1, data = df1)\n",
    "m3 <- lm(yvar ~ treat + xvar2, data = df1)\n",
    "m4 <- lm(yvar ~ treat + xvar1 + xvar2, data = df1)\n",
    "\n",
    "modelsummary(list(m1, m2, m3, m4),\n",
    "            stars = TRUE,                   \n",
    "            estimate = \"{estimate}{stars}\", \n",
    "            statistic = \"({std.error})\",\n",
    "            gof_map = c(\"nobs\", \"r.squared\", \"rmse\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MatchIt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `MatchIt` package offers a number of matching methods. Using these methods is (at least) a two-step process. First, use `matchit()` to generate a matchit object. This is function in which you will describe which the covariates that are driving treatment status, the matching methods to use, the number of matches, and the distance method to utilize with approximate matching methods. \n",
    "\n",
    "The `summary()` function will display balance statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "m.obj <- matchit(treat ~ xvar1 + xvar2, \n",
    "                    data = df1, \n",
    "                    method = \"nearest\", # try \"cem\" with the cutpoints argument \n",
    "                    ratio = 1,          # try 2\n",
    "                    distance = \"glm\")   # try \"mahalanobis\"\n",
    "summary(m.obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `match.data()` function will allow you to write the matched observations (with weigths and pairs/grouping information) to a new data frame for analysis.\n",
    "\n",
    "Let's see if we get a more accurate estimate of the effect of the treatment on the outcome using a simple difference in means with the \"pruned\" matched sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# store the MatchIt output as a new data frame\n",
    "dfmatched <- match.data(m.obj)\n",
    "\n",
    "dfmatched |>    group_by(treat) |> \n",
    "                summarize(\"mean of y\" = mean(yvar)) |>\n",
    "                pivot_wider(    names_from = treat,\n",
    "                                values_from = `mean of y`) |>\n",
    "                mutate(\"diff in means\" = `1` - `0`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine matching with regression methods to condition on other potential determinants of $Y$ using our matched sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "matched1 <- lm(yvar ~ treat, data = dfmatched)\n",
    "matched2 <- lm(yvar ~ treat + xvar1, data = dfmatched)\n",
    "matched3 <- lm(yvar ~ treat + xvar2, data = dfmatched)\n",
    "matched4 <- lm(yvar ~ treat + xvar1 + xvar2, data = dfmatched)\n",
    "\n",
    "modelsummary(list(m1, m2, m3, m4, \n",
    "                matched1, matched2, matched3, matched4),\n",
    "            stars = TRUE,                   \n",
    "            estimate = \"{estimate}{stars}\", \n",
    "            statistic = \"({std.error})\",\n",
    "            gof_map = c(\"nobs\", \"r.squared\", \"rmse\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare your regression output. Do the models using matched samples (4-6) get closer to the treatment effect of -6.1 than the non-matched models (1-3)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference-in-Differences\n",
    "\n",
    "DiD is probably the most popular impact evaluation design. For this example, we will use a dataset a student and I created to examine the impact of election alignment in NJ municipalities and school boards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# read in the data from GitHub \n",
    "njboards <- read_dta(\"https://raw.githubusercontent.com/bowendc/511_labs/refs/heads/main/nj_sb_small.dta\")\n",
    "\n",
    "head(njboards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# estimate quick 2x2 dd model. Note that treat identifies all units who eventually\n",
    "# adopt the election alignment with 1s, even prior to adoption. Post notes \n",
    "# all post-reform time periods.\n",
    "\n",
    "# to create an interaction term, simply include the product of two variables: treat*post\n",
    "# R will include both the constituent terms and the interaction term in the model.\n",
    "\n",
    "# lm_robust() from estimatr package conducts robust S.E. appropriate when you have heteroskedastic errors.\n",
    "\n",
    "dd <- lm_robust(median_salary_adj ~ treat*post,\n",
    "                data = njboards |> filter(todrop == 0))\n",
    "\n",
    "# view results. you could also use modelsummary\n",
    "summary(dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conduct a differential-timing DD, use two-way fixed effects. We need to change up the way we deal with treatment, however. Instead of creating the interaction of $TREAT \\times POST$, we create a dummy variable noting units which have adopted the treatment. For those units, the receive 1s in post-treatment time periods and 0s in pre-treatment periods. The variable `aligned_elections` below denotes school boards who aligned their elections after the Christie reform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# estimate fixed effects model (DD with differential timing)\n",
    "# here, in the | year + districtcode | portion of the function,\n",
    "# we specify the TWFE (time and district). The 0 part tells \n",
    "# R we are using any instrumental variables. \n",
    "# the final | districtcode requests that we cluster standard \n",
    "# errors by district since we have repeated observations by \n",
    "# district over time. \n",
    "\n",
    "fe <- felm(median_salary_adj ~ aligned_elections \n",
    "           | year + districtcode | 0 | districtcode, data = njboards)\n",
    "\n",
    "summary(fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, do we have evidence that aligned elections reduced teacher salaries, as Christie expected? How do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use leads and lag dummies to refine this approach. The leads can test to see if our treated units differed significantly from our control units pre-treatment. If they did, it raises questions about our DiD design. Again, we hopefully have comparable units pre-treatment. At the very least, we should be seeing little movement pre-treatment; that is, the difference between treated and control units do not change much prior to the treatment. If we find a great deal of pre-treatment movement, it undermines the parallel trends assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# recode data to create lead and lag variables\n",
    "njboards2 <- njboards |> mutate(lead1 = case_when(relyear == -1 ~ 1,\n",
    "                                                  relyear !=-1 ~ 0,\n",
    "                                                  TRUE ~ NA_real_),\n",
    "                                lead2 = case_when(relyear == -2 ~ 1,\n",
    "                                                  relyear !=-2 ~ 0,\n",
    "                                                  TRUE ~ NA_real_),\n",
    "                                lead3  = case_when(relyear == -3 ~ 1,\n",
    "                                                  relyear !=-3 ~ 0,\n",
    "                                                  TRUE ~ NA_real_),\n",
    "                                lead4 = case_when(relyear == -4 ~ 1,\n",
    "                                                  relyear !=-4 ~ 0,\n",
    "                                                  TRUE ~ NA_real_),\n",
    "                                lead5 = case_when(relyear == -5 ~ 1,\n",
    "                                                  relyear !=-5 ~ 0,\n",
    "                                                  TRUE ~ NA_real_),\n",
    "                                lag0 = case_when(relyear == 0 ~ 1,\n",
    "                                                  relyear != 0 ~ 0,\n",
    "                                                  TRUE ~ NA_real_),\n",
    "                                lag1 = case_when(relyear == 1 ~ 1,\n",
    "                                                 relyear != 1 ~ 0,\n",
    "                                                 TRUE ~ NA_real_),\n",
    "                                lag2 = case_when(relyear == 2 ~ 1,\n",
    "                                                 relyear != 2 ~ 0,\n",
    "                                                 TRUE ~ NA_real_),\n",
    "                                lag3 = case_when(relyear == 3 ~ 1,\n",
    "                                                 relyear != 3 ~ 0,\n",
    "                                                 TRUE ~ NA_real_),\n",
    "                                lag4 = case_when(relyear == 4 ~ 1,\n",
    "                                                 relyear != 4 ~ 0,\n",
    "                                                 TRUE ~ NA_real_))\n",
    "\n",
    "# re-estimate FE DD model, this time with leads and lags\n",
    "fe2 <- felm(median_salary_adj ~ lead5 + lead4 + lead3 + \n",
    "              lead2 + lead1 + lag1 + lag2 + lag3 + lag4\n",
    "            | year + districtcode | 0 | districtcode, data = njboards2)\n",
    "\n",
    "summary(fe2)\n",
    "\n",
    "\n",
    "# Tell R the order of our lead and lag vars\n",
    "plot_order <- c(\"lead5\", \"lead4\", \"lead3\", \"lead2\", \"lead1\", \"lag1\", \"lag2\", \"lag3\", \"lag4\")\n",
    "\n",
    "# create new data frame (tibble style) using stored results ordered in above order \n",
    "leadslags <- tibble(sd = c(fe2$cse[plot_order], 0),\n",
    "                    mean = c(coef(fe2)[plot_order], 0),\n",
    "                    label = c( -5,-4,-3,-2,-1,1,2,3,4, 0)) \n",
    "\n",
    "# plot using ggplot. Try switching geom_ribbon with geom_pointrange()\n",
    "leadslags |> ggplot(aes(x = label, y = mean, \n",
    "                        ymin = mean - 1.96*sd,\n",
    "                        ymax = mean + 1.96*sd)) +\n",
    "    geom_ribbon(alpha = .1) + \n",
    "    geom_line() + geom_hline(yintercept = 0, color = \"red\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
